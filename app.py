import streamlit as st

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import MinMaxScaler
import pickle


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="Churn Prediction App",
    page_icon="üìä",
    initial_sidebar_state="expanded",
)

if 'df_input' not in st.session_state:
    st.session_state['df_input'] = pd.DataFrame()

if 'df_predicted' not in st.session_state:
    st.session_state['df_predicted'] = pd.DataFrame()

numerical = ['tenure', 'monthlycharges', 'totalcharges']
categorical = ['gender',
'seniorcitizen',
'partner',
'dependents',
'phoneservice',
'multiplelines',
'internetservice',
'onlinesecurity',
'onlinebackup',
'deviceprotection',
'techsupport',
'streamingtv',
'streamingmovies',
'contract',
'paperlessbilling',
'paymentmethod']
le_enc_cols = ['gender', 'partner', 'dependents','paperlessbilling', 'phoneservice']
gender_map = {'male': 0, 'female': 1}
y_n_map = {'yes': 1, 'no': 0}

# –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å
model_file_path = "models/lr_model_churn_prediction.sav"
model = pickle.load(open(model_file_path, 'rb'))

encoding_model_file_path = "models/lr_model_churn_prediction_encode.sav"
encoding_model = pickle.load(open(encoding_model_file_path, 'rb'))

@st.cache_data
def convert_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

@st.cache_data
def predict_churn(data, treshold):
    scaler = MinMaxScaler()

    df_copy = data.copy()
    df_copy[numerical] = scaler.fit_transform(df_copy[numerical])

    for col in le_enc_cols:
        if col == 'gender':
            df_copy[col] = df_copy[col].map(gender_map)
        else:
            df_copy[col] = df_copy[col].map(y_n_map)

    dicts_df = df_copy[categorical + numerical].to_dict(orient='records')
    X = encoding_model.transform(dicts_df)
    y_pred = model.predict_proba(X)[:, 1]
    churn_descision = (y_pred >= treshold).astype(int)

    df_copy['churn_predicted'] = churn_descision
    df_copy['churn_predicted_probability'] = y_pred

    return df_copy



# SIDEBAR START
with st.sidebar:
    st.title("–í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö")

    tab1, tab2 = st.tabs(["–î–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞", "–í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é"])

    with tab1:
        uploaded_files = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª", accept_multiple_files=False, type=["csv", "xlsx"])
        if uploaded_files is not None:
            treshold = st.slider('–ü–æ—Ä–æ–≥ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –æ—Ç—Ç–æ–∫–∞', 0.0, 1.0, 0.5, 0.01, key="treshold")
            predict_button = st.button("–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞—Ç—å", type="primary", key="predict_button", use_container_width=True)
            st.session_state['df_input'] = pd.read_csv(uploaded_files)

            if predict_button:
                st.session_state['df_predicted'] = predict_churn(st.session_state['df_input'], treshold)
                

    with tab2:
        pass

# SIDEBAR END

# MAIN SECTION START
st.image('https://miro.medium.com/v2/resize:fit:1400/1*WqId29D5dN_8DhiYQcHa2w.png', width=400)
st.header("–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤")
with st.expander("–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"):
    st.write(
        """–í –¥–∞–Ω–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –∑–∞–¥–∞—á—É –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤.
        –î–ª—è —ç—Ç–æ–≥–æ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
        –î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∏–µ–Ω—Ç–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ —É—à–ª–∏ –∏–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å –≤ –∫–æ–º–ø–∞–Ω–∏–∏.
        –ù–∞—à–∞ –∑–∞–¥–∞—á–∞ - –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –æ—Ç—Ç–æ–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤.
        """)

# –í—ã–≤–æ–¥–∏–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–æ–≤.
if len(st.session_state['df_input']) > 0:
    
    if len(st.session_state['df_predicted']) == 0:
        st.subheader("–î–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞")
        st.write(st.session_state['df_input'])
    else:
        with st.expander("–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"):
            st.write(st.session_state['df_input'])


# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞.
if len(st.session_state['df_predicted']) > 0:
    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤")
    st.write(st.session_state['df_predicted'])
    res_all_csv = convert_to_csv(st.session_state['df_predicted'])
    st.download_button(
        "–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
        data=res_all_csv,
        file_name="result.csv",
        mime="text/csv",
    )

    


# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞.